{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd570c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20103682",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimate (MLE)\n",
    "One way to make more tractable predictions is to use the most likely model parameters which would generate the data rather than integrating out all parameters.\n",
    "$$P(X_\\text{new}|X_\\text{old})=P(X_\\text{new}|\\theta)$$\n",
    "where $$\\theta = \\text{argmax}_\\theta P(X_\\text{old}|\\theta)$$\n",
    "We use $D$ to refer to old data in some cases. <br>\n",
    "Often it is assumed that the data is independent and identically distributed, which means:\n",
    "$$P(D|\\theta)=\\prod_i P(D_i|\\theta)$$\n",
    "Another common practice is to use the log likelihood of the data, as $$\\text{argmax} (x) = \\text{argmax} (\\log(x))$$\n",
    "This turns the above product into a sum:\n",
    "$$P(D|\\theta)\\propto \\sum_i \\log(P(D_i|\\theta))$$\n",
    "This is much more numerically stable as a product of many numbers less than 1 gets very very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5e23f",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d44b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
