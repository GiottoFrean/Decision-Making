{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attempted-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0,'../../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "peripheral-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-arrival",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In inference problems we want to figure out a distribution over a variable given other variables we do and do not know. We want:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  P(Y|X_\\text{known}) &= \\sum_{X_\\text{unknown}}P(Y,X_\\text{unknown}|X_\\text{known}) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "So we condition on known variables and then marginalize out the unknown variables we are not interested in. <br>\n",
    "In Bayesian networks we can do exact inference with the factor representation.<br>\n",
    "If we can represent a joint distribution with a factor, then conditioning and marginalizing are very simple, just using the formula above. Say you are interested in knowing whether you will need to get tea from the shop on the way home, given who is at home (using 0 for False and 1 for True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaged-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of tea  mums home  dads home  Values (10 dp)\n",
      "0           0          0          0.15\n",
      "0           0          1          0.05\n",
      "0           1          0          0.1\n",
      "0           1          1          0.35\n",
      "1           0          0          0.0\n",
      "1           0          1          0.1\n",
      "1           1          0          0.05\n",
      "1           1          1          0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tea_factor = factors.Factor([\"out of tea\",\"mums home\",\"dads home\"],[2,2,2])\n",
    "tea_factor.set([0,0,0],0.15)\n",
    "tea_factor.set([0,0,1],0.05)\n",
    "tea_factor.set([0,1,0],0.1)\n",
    "tea_factor.set([0,1,1],0.35)\n",
    "tea_factor.set([1,0,0],0.0)\n",
    "tea_factor.set([1,0,1],0.1)\n",
    "tea_factor.set([1,1,0],0.05)\n",
    "tea_factor.set([1,1,1],0.2)\n",
    "print(tea_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-halifax",
   "metadata": {},
   "source": [
    "And you know that dad isn't home, but you aren't sure about mum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of tea  Values (10 dp)\n",
      "0           0.8333333333\n",
      "1           0.1666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_dads_home_to_0 = factors.drop_variables(tea_factor,[\"dads home\"],[0])\n",
    "conditoned_dads_home_0 = factors.condition(set_dads_home_to_0)\n",
    "marginalize_mums_home = factors.marginalize(conditoned_dads_home_0,[\"mums home\"])\n",
    "print(marginalize_mums_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-fireplace",
   "metadata": {},
   "source": [
    "This can be checked very easily with rejection sampling (explained in next notebook) just using samples from the joint and discarding those for which the conditional is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharing-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated not out of tea prob: 0.8241721854304636\n",
      "estimated out of tea prob    : 0.17582781456953642\n"
     ]
    }
   ],
   "source": [
    "array = tea_factor.array\n",
    "indexes = tea_factor.indexes\n",
    "value_grid = np.mgrid[:2,:2,:2]\n",
    "total_not_out_of_tea = 0\n",
    "total_out_of_tea = 0\n",
    "for sample in range(10000):\n",
    "    row = np.random.choice(np.arange(8),p=tea_factor.array.reshape(-1))\n",
    "    setting = indexes[row]\n",
    "    if(setting[2]==0):\n",
    "        if(setting[0]==0):\n",
    "            total_not_out_of_tea+=1\n",
    "        else:\n",
    "            total_out_of_tea+=1\n",
    "print(\"estimated not out of tea prob:\",total_not_out_of_tea/(total_not_out_of_tea+total_out_of_tea))\n",
    "print(\"estimated out of tea prob    :\",total_out_of_tea/(total_not_out_of_tea+total_out_of_tea))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-graduate",
   "metadata": {},
   "source": [
    "So, exact inference on a factor is easy. However, creating the full joint table is very expensive for high numbers of variables. Fortunately it is possible to condition and marginalize out variables at the deconstructed level:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-circuit",
   "metadata": {},
   "source": [
    "# The Sum-Product Algorithm\n",
    "Say we have a joint probability which can be written in terms of conditionals, e.g: <br>\n",
    "$$P(A,B,C,D)=P(D|B)P(B|A,C)P(A)P(C)$$\n",
    "which in turn can be written in terms of factors:\n",
    "$$P(A,B,C,D)=\\phi_1(D,B)\\phi_2(B,A,C)\\phi_3(A)\\phi_4(C)$$\n",
    "Then we can condition on each variable we know and repeatedly perform factor multiplication and marginalization of unknown variables. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "through-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1 = factors.Factor([\"D\",\"B\"],[2,2])\n",
    "factor1.set_all([0.6,0.3,0.4,0.7])\n",
    "factor2 = factors.Factor([\"B\",\"A\",\"C\"],[2,2,2])\n",
    "factor2.set_all([0.2,0.6,0.1,0.5,0.8,0.4,0.9,0.5])\n",
    "factor3 = factors.Factor([\"A\"],2)\n",
    "factor3.set_all([0.25,0.75])\n",
    "factor4 = factors.Factor([\"C\"],2)\n",
    "factor4.set_all([0.65,0.35])\n",
    "all_factors = [factor1,factor2,factor3,factor4]\n",
    "evidence_names = [\"D\"]\n",
    "evidence_vals = [1]\n",
    "unknown_names = [\"A\",\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "affiliated-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_product_variable_elimination(all_factors,known_vars,evidence,unknown_vars):\n",
    "    new_factors = []\n",
    "    for f in all_factors:\n",
    "        deleted_f = factors.drop_variables(f,known_vars,evidence)\n",
    "        if(deleted_f!=None):\n",
    "            new_factors.append(deleted_f)\n",
    "    \n",
    "    for unknown_var in unknown_vars:\n",
    "        factors_to_combine = []\n",
    "        factors_to_exclude = []\n",
    "        for f in new_factors:\n",
    "            if(unknown_var in f.names):\n",
    "                factors_to_combine.append(f)\n",
    "            else:\n",
    "                factors_to_exclude.append(f)\n",
    "        new_factors = factors_to_exclude\n",
    "        if(len(factors_to_combine)>0):\n",
    "            combined_factor = factors.multiple_factor_product(factors_to_combine)\n",
    "            combined_factor = factors.marginalize(combined_factor,[unknown_var])\n",
    "            if(not isinstance(combined_factor,(int,float))):\n",
    "                new_factors.append(combined_factor)\n",
    "    if(len(new_factors)>1):\n",
    "        combined_factor = factors.multiple_factor_product(new_factors)\n",
    "        new_factors = [combined_factor]\n",
    "    return factors.condition(new_factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "historic-corner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B  Values (10 dp)\n",
      "0  0.1708299758\n",
      "1  0.8291700242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sum_product_variable_elimination(all_factors,evidence_names,evidence,unknown_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-annotation",
   "metadata": {},
   "source": [
    "### We can check this gives the same answer with the full joint factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "western-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_joint_elimination(all_factors,known_vars,evidence,unknown_vars):\n",
    "    full_joint_factor = factors.multiple_factor_product(all_factors)\n",
    "    set_vars = factors.drop_variables(full_joint_factor,known_vars,evidence)\n",
    "    marginalized = factors.marginalize(set_vars,unknown_vars)\n",
    "    if(marginalized!=None):\n",
    "        normalized = factors.condition(marginalized)\n",
    "        return normalized\n",
    "    else:\n",
    "        normalized = factors.condition(set_vars)\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "useful-consultancy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B  Values (10 dp)\n",
      "0  0.1708299758\n",
      "1  0.8291700242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_joint_elimination(all_factors,evidence_names,evidence,unknown_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-affiliation",
   "metadata": {},
   "source": [
    "Code to run these algorithms is in the exact_inference.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "listed-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import exact_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "impossible-target",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D  Values (10 dp)\n",
      "0  0.402\n",
      "1  0.598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_sumP = exact_inference.sum_product_variable_elimination(all_factors,[\"A\"],[0],[\"B\",\"C\"])\n",
    "print(f_sumP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bottom-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D  Values (10 dp)\n",
      "0  0.402\n",
      "1  0.598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_full_table = exact_inference.full_joint_elimination(all_factors,[\"A\"],[0],[\"B\",\"C\"])\n",
    "print(f_full_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-commissioner",
   "metadata": {},
   "source": [
    "I am fairly sure the sum product code is correct, but there might be some edge case issues.\n",
    "Notebook 2 in this chapter discusses approximations with sampling. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
