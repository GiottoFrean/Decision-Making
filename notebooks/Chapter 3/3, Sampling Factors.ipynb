{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rural-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0,'../../modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a92bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import factors\n",
    "import exact_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d153fee",
   "metadata": {},
   "source": [
    "# Sampling top down\n",
    "When sampling a pgm one option is to make the full joint and sample from that. This requires making one large factor which might not be viable. Another option is to sample the top (root) nodes first, then condition all further samples on their parent nodes. This means you can sample the full joint without needing to merge all factors. <br>\n",
    "Example: Making the graph $A$ and $B$ (independent) cause $C$ which then causes $D$ and $E$ (independent given $C$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4bec9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  Values (10 dp)\n",
      "0  0.3485497205\n",
      "1  0.6514502795\n",
      "\n",
      "B  Values (10 dp)\n",
      "0  0.0794785344\n",
      "1  0.9205214656\n",
      "\n",
      "C  A  B  Values (10 dp)\n",
      "0  0  0  0.2523884772\n",
      "0  0  1  0.3357885935\n",
      "0  1  0  0.225960047\n",
      "0  1  1  0.4307946056\n",
      "1  0  0  0.7476115228\n",
      "1  0  1  0.6642114065\n",
      "1  1  0  0.774039953\n",
      "1  1  1  0.5692053944\n",
      "\n",
      "D  C  Values (10 dp)\n",
      "0  0  0.5741510951\n",
      "0  1  0.2652084461\n",
      "1  0  0.4258489049\n",
      "1  1  0.7347915539\n",
      "\n",
      "E  C  Values (10 dp)\n",
      "0  0  0.9837327189\n",
      "0  1  0.401983203\n",
      "1  0  0.0162672811\n",
      "1  1  0.598016797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# making random values\n",
    "A = factors.Factor([\"A\"],[2])\n",
    "B = factors.Factor([\"B\"],[2])\n",
    "C = factors.Factor([\"C\",\"A\",\"B\"],[2,2,2])\n",
    "D = factors.Factor([\"D\",\"C\"],[2,2])\n",
    "E = factors.Factor([\"E\",\"C\"],[2,2])\n",
    "all_factors = []\n",
    "for f in [A,B,C,D,E]:\n",
    "    f.set_all(np.random.rand(np.prod(f.array.shape)))\n",
    "    cond_f = factors.condition(f,list(f.names[1:]))\n",
    "    all_factors.append(cond_f)\n",
    "for f in all_factors:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "17115b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes the first variable in each factor is dependent on all others in the factor\n",
    "def joint_sample_top_down(all_factors):\n",
    "    assigned_variable_names = []\n",
    "    variable_assignments = []\n",
    "    remaining_factors = all_factors.copy()\n",
    "    \n",
    "    while(len(remaining_factors)>0):\n",
    "        new_assigned_variable_names = assigned_variable_names.copy()\n",
    "        new_variable_assignments = variable_assignments.copy()\n",
    "        new_remaining_factors = []\n",
    "        for f in remaining_factors:\n",
    "            if(len(f.names)==1 or np.prod([i in assigned_variable_names for i in f.names[1:]])==1):\n",
    "                conditioned_factor = factors.drop_variables(f,assigned_variable_names,variable_assignments)\n",
    "                new_variable_assignments.append(factors.sample(conditioned_factor,1)[0][0])\n",
    "                new_assigned_variable_names.append(f.names[0])\n",
    "            else:\n",
    "                new_remaining_factors.append(f)\n",
    "        assigned_variable_names = new_assigned_variable_names\n",
    "        variable_assignments = new_variable_assignments\n",
    "        remaining_factors = new_remaining_factors\n",
    "    return assigned_variable_names,variable_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b957d8",
   "metadata": {},
   "source": [
    "**Checking the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6d66f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.3876\n",
      "1  0.6124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_samples = []\n",
    "for n in range(5000):\n",
    "    names,assignments = joint_sample_top_down(all_factors)\n",
    "    all_samples.append(assignments)\n",
    "all_samples = np.array(all_samples)\n",
    "prob_C_sampled = factors.Factor([\"C\"],[2])\n",
    "prob_C_sampled.set([0],np.sum(all_samples[:,2]==0)/all_samples.shape[0])\n",
    "prob_C_sampled.set([1],np.sum(all_samples[:,2]==1)/all_samples.shape[0])\n",
    "print(prob_C_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dbf13cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.3847643398\n",
      "1  0.6152356602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_C_exact = exact_inference.sum_product_variable_elimination(all_factors,[],[],[\"A\",\"B\",\"D\",\"E\"])\n",
    "print(prob_C_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da6d04",
   "metadata": {},
   "source": [
    "# Direct Sampling, Likelihood weighted sampling, Gibbs Sampling\n",
    "One problem with the above is that you can only sample the full joint this way. But often we need to sample a conditional distribution instead. If it is difficult to sample if the observed variables are the bottom nodes in a pgm, as it means sampling all parent nodes backwards. Whereas if the root nodes are known then it is easy, as above. There are a few options to deal with this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd470bb",
   "metadata": {},
   "source": [
    "### Direct Sampling\n",
    "With direct sampling you sample the full joint like above and simply throw away all samples which don't match the observed variables. This is basically rejection sampling. Say we want to know $P(C)$ as above, but only if $A$ is 0 (using the same samples as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e5f4cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.3337209302\n",
      "1  0.6662790698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples_where_A0 = all_samples[all_samples[:,0]==0]\n",
    "prob_C_given_A_sampled = factors.Factor([\"C\"],[2])\n",
    "prob_C_given_A_sampled.set([0],np.sum(samples_where_A0[:,2]==0)/samples_where_A0.shape[0])\n",
    "prob_C_given_A_sampled.set([1],np.sum(samples_where_A0[:,2]==1)/samples_where_A0.shape[0])\n",
    "print(prob_C_given_A_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41774c",
   "metadata": {},
   "source": [
    "**checking the approximation is close to the exact value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f71ea0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.3291600744\n",
      "1  0.6708399256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob_C_given_A_exact = exact_inference.sum_product_variable_elimination(all_factors,[\"A\"],[0],[\"B\",\"D\",\"E\"])\n",
    "print(prob_C_given_A_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded5825",
   "metadata": {},
   "source": [
    "### Likelihood weighting\n",
    "With Likelihood weighting you sample all unknown variables as normal, but set the known variables to their value. This means all children are correctly sampled based on the parent values, but the parents are not sampled based on the children. So, you are sampling correct looking variables, but with a slightly incorect distribution. This is Importance Sampling applied to factors.\n",
    "$$P(X=x_n) = \\int \\mathbb{1}(x=x_n)p(x) dx \\approx \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}(x_i=x_n) $$\n",
    "Becomes:\n",
    "$$\\int \\mathbb{1}(x=x_n)p(x) dx \\approx \\frac{1}{\\sum \\frac{p(x_n)}{q(x_n)}} \\sum_{i=1}^N \\frac{\\mathbb{1}(x_i=x_n)p(x_n)}{q(x_n)} $$\n",
    "Using the formula for normalized importance sampling. The distribution we sample from, $q(x)$, is constructed as above by setting observed values. The true probability $p(x)$ is the multiplication of all of the normalized conditional probabilities regardless of whether the observed value was set or not. $q(x)$ is the same, but $1$ whereever the value was assigned by evidence. Therefore, $\\frac{p(x)}{q(x)}$ (the weight) is just the product of the probabilities at the observed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6cfb1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes the first variable in each factor is dependent on all others in the factor\n",
    "def likelihood_weighting_top_down(all_factors,known_vars,evidence):\n",
    "    assigned_variable_names = []\n",
    "    variable_assignments = []\n",
    "    weight = 1\n",
    "    remaining_factors = all_factors.copy()\n",
    "    \n",
    "    while(len(remaining_factors)>0):\n",
    "        new_assigned_variable_names = assigned_variable_names.copy()\n",
    "        new_variable_assignments = variable_assignments.copy()\n",
    "        new_remaining_factors = []\n",
    "        for f in remaining_factors:\n",
    "            if(len(f.names)==1 or np.prod([i in assigned_variable_names for i in f.names[1:]])==1):\n",
    "                var_dropped_factor = factors.drop_variables(f,assigned_variable_names,variable_assignments)\n",
    "                conditioned_factor = factors.condition(var_dropped_factor)\n",
    "                if(f.names[0] in known_vars):\n",
    "                    evid = evidence[known_vars.index(f.names[0])]\n",
    "                    new_variable_assignments.append(evid)\n",
    "                    weight *= conditioned_factor.get([evid])\n",
    "                else:\n",
    "                    sample = factors.sample(conditioned_factor,1)[0][0]\n",
    "                    new_variable_assignments.append(sample)\n",
    "                    \n",
    "                new_assigned_variable_names.append(f.names[0])\n",
    "            else:\n",
    "                new_remaining_factors.append(f)\n",
    "        assigned_variable_names = new_assigned_variable_names\n",
    "        variable_assignments = new_variable_assignments\n",
    "        remaining_factors = new_remaining_factors\n",
    "    return assigned_variable_names,variable_assignments,weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd02764",
   "metadata": {},
   "source": [
    "**Checking results again:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7f0e861b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.352\n",
      "1  0.648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_LW_samples = []\n",
    "all_LW_weights = []\n",
    "for n in range(1000):\n",
    "    names,assignments,weight = likelihood_weighting_top_down(all_factors,[\"A\"],[0])\n",
    "    all_LW_samples.append(assignments)\n",
    "    all_LW_weights.append(weight)\n",
    "all_LW_samples = np.array(all_LW_samples)\n",
    "all_LW_weights = np.array(all_LW_weights)\n",
    "\n",
    "prob_C_given_A_LW_sampled = factors.Factor([\"C\"],[2])\n",
    "prob_C_given_A_LW_sampled.set([0],np.sum(all_LW_weights*(all_LW_samples[:,2]==0))/np.sum(all_LW_weights))\n",
    "prob_C_given_A_LW_sampled.set([1],np.sum(all_LW_weights*(all_LW_samples[:,2]==1))/np.sum(all_LW_weights))\n",
    "print(prob_C_given_A_LW_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f2bb8",
   "metadata": {},
   "source": [
    "### Gibbs sampling\n",
    "An alternative was to do inference is to generate samples of the conditional distribution using gibbs sampling. Gibbs starts with a random set of variable values and proceedes by conditioning each variable on all variables within its markov blanket. This makes it tractable. It is a variant of the Markov Chain Monte Carlo (MCMC) technique for generating samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "8dbdd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GibbsStep(all_variable_markov_blankets,fixed_variables,all_variable_names,current_state_values):\n",
    "    for var_name in all_variable_names:\n",
    "        if(not var_name in fixed_variables):\n",
    "            joint = all_variable_markov_blankets[all_variable_names.index(var_name)]\n",
    "            index = all_variable_names.index(var_name)\n",
    "            other_var_names = list(all_variable_names[:index])+list(all_variable_names[(index+1):])\n",
    "            other_var_vals = list(current_state_values[:index])+list(current_state_values[(index+1):])\n",
    "            slc = [slice(None)]*len(joint.names)\n",
    "            for i in range(len(all_variable_names)):\n",
    "                if(all_variable_names[i] in joint.names):\n",
    "                    slc[joint.names.index(all_variable_names[i])]=slice(current_state_values[i],current_state_values[i]+1)\n",
    "            joint_index = joint.names.index(var_name)\n",
    "            slc[joint_index]=slice(0,joint.array.shape[joint_index])\n",
    "            array_slice = np.squeeze(joint.array[tuple(slc)])\n",
    "            norm_array_slice = array_slice/np.sum(array_slice)\n",
    "            cond_joint = factors.drop_variables(joint,other_var_names,other_var_vals)\n",
    "            sample = np.random.choice(np.arange(joint.array.shape[joint_index]),1,p=norm_array_slice)\n",
    "            #print(sample)\n",
    "            current_state_values[index]=sample\n",
    "    return current_state_values\n",
    "\n",
    "def GibbsSampling(all_factors,known_vars,evidence,N):\n",
    "    all_names = []\n",
    "    for f in all_factors:\n",
    "        all_names+=list(f.names)\n",
    "    all_names = list(np.unique(all_names))\n",
    "    current_state = np.zeros(len(all_names)).astype(int) # start with 0's\n",
    "    for i,name in enumerate(all_names):\n",
    "        for f in all_factors: # find a factor to get the sample\n",
    "            if(name in f.names):\n",
    "                shape = f.array.shape[list(f.names).index(name)]\n",
    "                current_state[i]=np.random.randint(0,shape)\n",
    "                break\n",
    "    for i in range(len(known_vars)):\n",
    "        current_state[all_names.index(known_vars[i])]=evidence[i]\n",
    "    \n",
    "    all_variable_markov_blankets = []\n",
    "    for var_name in all_names:\n",
    "        markov_blanket = []\n",
    "        for f in all_factors:\n",
    "            if(var_name in f.names):\n",
    "                markov_blanket.append(f)\n",
    "        all_variable_markov_blankets.append(factors.multiple_factor_product(markov_blanket))\n",
    "    \n",
    "    all_visited_states = []\n",
    "    for n in range(N):\n",
    "        current_state = GibbsStep(all_variable_markov_blankets,known_vars,all_names,current_state)\n",
    "        all_visited_states.append(current_state.copy())\n",
    "    return np.array(all_visited_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "93926dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = GibbsSampling(all_factors,[\"A\"],[0],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "3dd84a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3414141414141414\n"
     ]
    }
   ],
   "source": [
    "average_C_given_A = np.mean(samples[100::10]==0,axis=0)[2]\n",
    "print(average_C_given_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df547deb",
   "metadata": {},
   "source": [
    "As expected, this value matches the exact value closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "77c578eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C  Values (10 dp)\n",
      "0  0.3291600744\n",
      "1  0.6708399256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(exact_inference.sum_product_variable_elimination(all_factors,[\"A\"],[0],[\"B\",\"D\",\"E\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
